{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4f524e-a70b-497b-853e-7f4fb66904a9",
   "metadata": {},
   "source": [
    "# Multi-Agent Research Assistant\n",
    "## (using multi-agent collaboration system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e4ca4-7456-4120-a59e-b7c8ed6a52e2",
   "metadata": {},
   "source": [
    "Your task is to develop a multi-agent AI system that can autonomously research a complex\n",
    "topic, synthesize information from multiple sources, and generate a comprehensive report.\n",
    "This system should demonstrate agentic behaviors, including planning, reasoning, task\n",
    "decomposition, and collaboration between specialized agents.\n",
    "Requirements:\n",
    "The system must include at least three specialized agents with distinct roles (e.g.,\n",
    "researcher, analyzer, writer)\n",
    "Agents must communicate with each other to coordinate their work\n",
    "The system should be able to handle a research query on any business or technical\n",
    "topic\n",
    "It must autonomously plan its approach to the research task\n",
    "It should search for and retrieve information from the web and/or provided documents\n",
    "It must evaluate source credibility and resolve conflicting information\n",
    "The final output should be a well-structured report with proper citations\n",
    "The system should maintain a traceable chain of reasoning for its conclusions\n",
    "\n",
    "In this project, we will use 3 agents\n",
    "\n",
    "- Researcher Agent \n",
    "- Analyzer Agent\n",
    "- Writer Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030a2c5-78ba-401d-9eb9-ae4b41e10296",
   "metadata": {},
   "source": [
    "In this project, we will use a **Hierarchial Process**, where crewAI creates a manager to delegate task to all the 3 agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199acfb5-de39-4b65-ac48-87b4e6a62237",
   "metadata": {},
   "source": [
    "## Step 01. Installing crewai and crewai_tools libraries\n",
    "\n",
    "**Note:** crewai requires Python version >=3.10 and <=3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d5b490-9bf5-4391-8fd6-9c93eacf5228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66850ce6-a86f-45e4-9f36-3d58b9bcd2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai\n",
      "  Downloading crewai-0.120.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting appdirs>=1.4.4 (from crewai)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting auth0-python>=4.7.1 (from crewai)\n",
      "  Using cached auth0_python-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting blinker>=1.9.0 (from crewai)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting chromadb>=0.5.23 (from crewai)\n",
      "  Using cached chromadb-1.0.9-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting click>=8.1.7 (from crewai)\n",
      "  Using cached click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting instructor>=1.3.3 (from crewai)\n",
      "  Using cached instructor-1.8.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting json-repair>=0.25.2 (from crewai)\n",
      "  Using cached json_repair-0.44.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: json5>=0.10.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai) (0.12.0)\n",
      "Collecting jsonref>=1.1.0 (from crewai)\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting litellm==1.68.0 (from crewai)\n",
      "  Downloading litellm-1.68.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting openai>=1.13.3 (from crewai)\n",
      "  Using cached openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting openpyxl>=3.1.5 (from crewai)\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.30.0 (from crewai)\n",
      "  Using cached opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.30.0 (from crewai)\n",
      "  Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pdfplumber>=0.11.4 (from crewai)\n",
      "  Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pydantic>=2.4.2 (from crewai)\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting python-dotenv>=1.0.0 (from crewai)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pyvis>=0.3.2 (from crewai)\n",
      "  Using cached pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2024.9.11 (from crewai)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tomli-w>=1.1.0 (from crewai)\n",
      "  Using cached tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tomli>=2.0.2 (from crewai)\n",
      "  Downloading tomli-2.2.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting uv>=0.4.25 (from crewai)\n",
      "  Using cached uv-0.7.5-py3-none-win_amd64.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from litellm==1.68.0->crewai)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai) (0.28.1)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm==1.68.0->crewai)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai) (4.23.0)\n",
      "Collecting openai>=1.13.3 (from crewai)\n",
      "  Using cached openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm==1.68.0->crewai)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting tokenizers (from litellm==1.68.0->crewai)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting cryptography>=43.0.1 (from auth0-python>=4.7.1->crewai)\n",
      "  Downloading cryptography-45.0.1-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting pyjwt>=2.8.0 (from auth0-python>=4.7.1->crewai)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: requests>=2.32.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from auth0-python>=4.7.1->crewai) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=2.2.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from auth0-python>=4.7.1->crewai) (2.4.0)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fastapi==0.115.9 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting numpy>=1.22.5 (from chromadb>=0.5.23->crewai)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached posthog-4.0.1-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.5.23->crewai) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.23->crewai)\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm>=4.65.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.5.23->crewai) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb>=0.5.23->crewai)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=0.5.23->crewai)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.5.23->crewai)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=0.5.23->crewai)\n",
      "  Using cached starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from click>=8.1.7->crewai) (0.4.6)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor>=1.3.3->crewai)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jiter<0.9,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor>=1.3.3->crewai)\n",
      "  Downloading pydantic_core-2.34.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb>=0.5.23->crewai)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.13.3->crewai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.13.3->crewai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
      "Collecting et-xmlfile (from openpyxl>=3.1.5->crewai)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.30.0->crewai)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm==1.68.0->crewai)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
      "  Using cached opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.33.1->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk>=1.30.0->crewai)\n",
      "  Using cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber>=0.11.4->crewai)\n",
      "  Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Pillow>=9.1 (from pdfplumber>=0.11.4->crewai)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
      "  Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber>=0.11.4->crewai) (3.4.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.4.2->crewai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.0 (from instructor>=1.3.3->crewai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.4.2->crewai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pyvis>=0.3.2->crewai) (9.2.0)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis>=0.3.2->crewai)\n",
      "  Using cached jsonpickle-4.0.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting networkx>=1.11 (from pyvis>=0.3.2->crewai)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm==1.68.0->crewai)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (3.10)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.5.23->crewai)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api>=1.30.0->crewai)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpx>=0.23.0->litellm==1.68.0->crewai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpx>=0.23.0->litellm==1.68.0->crewai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.68.0->crewai) (0.16.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm==1.68.0->crewai)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.68.0->crewai) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (0.25.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
      "  Using cached opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
      "  Using cached opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm==1.68.0->crewai)\n",
      "  Using cached huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.1.7 (from crewai)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
      "  Downloading watchfiles-1.0.5-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from cffi>=1.14->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading crewai-0.120.1-py3-none-any.whl (310 kB)\n",
      "Downloading litellm-1.68.0-py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/7.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.6/7.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.7/7.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 9.0 MB/s eta 0:00:00\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached auth0_python-4.9.0-py3-none-any.whl (135 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached chromadb-1.0.9-cp39-abi3-win_amd64.whl (18.9 MB)\n",
      "Using cached fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Using cached instructor-1.8.2-py3-none-any.whl (91 kB)\n",
      "Using cached json_repair-0.44.1-py3-none-any.whl (22 kB)\n",
      "Using cached jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Using cached openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "Using cached pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Using cached pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 13.5 MB/s eta 0:00:00\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading tomli-2.2.1-cp312-cp312-win_amd64.whl (109 kB)\n",
      "Using cached tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
      "Using cached uv-0.7.5-py3-none-win_amd64.whl (18.4 MB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading cryptography-45.0.1-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  3.4/3.4 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 15.4 MB/s eta 0:00:00\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  4.2/4.3 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 18.3 MB/s eta 0:00:00\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached jsonpickle-4.0.5-py3-none-any.whl (46 kB)\n",
      "Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 5.0/12.6 MB 23.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 5.2/12.7 MB 26.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 22.1 MB/s eta 0:00:00\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 31.0 MB/s eta 0:00:00\n",
      "Using cached posthog-4.0.1-py2.py3-none-any.whl (92 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 13.5 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Using cached google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Using cached huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading watchfiles-1.0.5-cp312-cp312-win_amd64.whl (291 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53914 sha256=ef40463c3c790667574d257714457cf75000103496ec36206b0c28ff437a45b4\n",
      "  Stored in directory: c:\\users\\aashi-gupta1\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, flatbuffers, durationpy, appdirs, zipp, wrapt, websockets, uv, typing-inspection, tqdm, tomli-w, tomli, tenacity, sympy, shellingham, regex, python-dotenv, pyreadline3, pyproject_hooks, pypdfium2, pyjwt, pydantic-core, pyasn1, protobuf, propcache, Pillow, orjson, opentelemetry-util-http, oauthlib, numpy, networkx, multidict, mmh3, mdurl, jsonref, jsonpickle, json-repair, jiter, importlib-resources, httptools, grpcio, fsspec, frozenlist, filelock, et-xmlfile, docstring-parser, distro, click, cachetools, blinker, bcrypt, backoff, asgiref, annotated-types, aiohappyeyeballs, yarl, watchfiles, uvicorn, tiktoken, starlette, rsa, requests-oauthlib, pydantic, pyasn1-modules, posthog, opentelemetry-proto, openpyxl, markdown-it-py, importlib-metadata, humanfriendly, huggingface-hub, googleapis-common-protos, deprecated, cryptography, build, aiosignal, tokenizers, rich, pyvis, pdfminer.six, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, google-auth, fastapi, coloredlogs, aiohttp, typer, pdfplumber, opentelemetry-semantic-conventions, onnxruntime, litellm, kubernetes, auth0-python, opentelemetry-sdk, opentelemetry-instrumentation, instructor, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, crewai\n",
      "Successfully installed Pillow-11.2.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.9.0 backoff-2.2.1 bcrypt-4.3.0 blinker-1.9.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.9 click-8.1.8 coloredlogs-15.0.1 crewai-0.120.1 cryptography-45.0.1 deprecated-1.2.18 distro-1.9.0 docstring-parser-0.16 durationpy-0.10 et-xmlfile-2.0.0 fastapi-0.115.9 filelock-3.18.0 flatbuffers-25.2.10 frozenlist-1.6.0 fsspec-2025.3.2 google-auth-2.40.1 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 huggingface-hub-0.31.2 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 instructor-1.8.2 jiter-0.8.2 json-repair-0.44.1 jsonpickle-4.0.5 jsonref-1.1.0 kubernetes-32.0.1 litellm-1.68.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 multidict-6.4.3 networkx-3.4.2 numpy-2.2.5 oauthlib-3.2.2 onnxruntime-1.22.0 openai-1.75.0 openpyxl-3.1.5 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 orjson-3.10.18 pdfminer.six-20250327 pdfplumber-0.11.6 posthog-4.0.1 propcache-0.3.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.4 pydantic-core-2.33.2 pyjwt-2.10.1 pypdfium2-4.30.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.0 pyvis-0.3.2 regex-2024.11.6 requests-oauthlib-2.0.0 rich-13.9.4 rsa-4.9.1 shellingham-1.5.4 starlette-0.45.3 sympy-1.14.0 tenacity-9.1.2 tiktoken-0.9.0 tokenizers-0.21.1 tomli-2.2.1 tomli-w-1.2.0 tqdm-4.67.1 typer-0.15.4 typing-inspection-0.4.0 uv-0.7.5 uvicorn-0.34.2 watchfiles-1.0.5 websockets-15.0.1 wrapt-1.17.2 yarl-1.20.0 zipp-3.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0bf8227-49f2-44ae-97f6-3c29e6c7b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai_tools\n",
      "  Using cached crewai_tools-0.45.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: chromadb>=0.4.22 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (1.0.9)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (8.1.8)\n",
      "Requirement already satisfied: crewai>=0.119.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (0.120.1)\n",
      "Collecting docker>=7.1.0 (from crewai_tools)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting embedchain>=0.1.114 (from crewai_tools)\n",
      "  Using cached embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting lancedb>=0.5.4 (from crewai_tools)\n",
      "  Using cached lancedb-0.22.0-cp39-abi3-win_amd64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: openai>=1.12.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (1.75.0)\n",
      "Requirement already satisfied: pydantic>=2.6.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (2.11.4)\n",
      "Collecting pyright>=1.1.350 (from crewai_tools)\n",
      "  Using cached pyright-1.1.400-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pytube>=15.0.0 (from crewai_tools)\n",
      "  Using cached pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai_tools) (2.32.3)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools) (0.34.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (2.2.5)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (4.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (4.13.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.15.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chromadb>=0.4.22->crewai_tools) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from fastapi==0.115.9->chromadb>=0.4.22->crewai_tools) (0.45.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from click>=8.1.8->crewai_tools) (0.4.6)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.4.4)\n",
      "Requirement already satisfied: auth0-python>=4.7.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (4.9.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.9.0)\n",
      "Requirement already satisfied: instructor>=1.3.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.8.2)\n",
      "Requirement already satisfied: json-repair>=0.25.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (0.44.1)\n",
      "Requirement already satisfied: json5>=0.10.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (0.12.0)\n",
      "Requirement already satisfied: jsonref>=1.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.1.0)\n",
      "Requirement already satisfied: litellm==1.68.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.68.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.5 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (3.1.5)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: pdfplumber>=0.11.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (0.11.6)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.1.0)\n",
      "Requirement already satisfied: pyvis>=0.3.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (0.3.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (2024.11.6)\n",
      "Requirement already satisfied: tomli-w>=1.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (1.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (2.2.1)\n",
      "Requirement already satisfied: uv>=0.4.25 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from crewai>=0.119.0->crewai_tools) (0.7.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai>=0.119.0->crewai_tools) (3.11.18)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai>=0.119.0->crewai_tools) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai>=0.119.0->crewai_tools) (3.1.6)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from litellm==1.68.0->crewai>=0.119.0->crewai_tools) (0.9.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from docker>=7.1.0->crewai_tools) (310)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from docker>=7.1.0->crewai_tools) (2.4.0)\n",
      "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from embedchain>=0.1.114->crewai_tools) (4.13.4)\n",
      "Collecting chromadb>=0.4.22 (from crewai_tools)\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4.0,>=0.3.18 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from embedchain>=0.1.114->crewai_tools) (0.3.42)\n",
      "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached mem0ai-0.1.99-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb>=0.4.22->crewai_tools)\n",
      "  Using cached posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=2.0.27 (from embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.4.22->crewai_tools)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tokenizers (from litellm==1.68.0->crewai>=0.119.0->crewai_tools)\n",
      "  Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting deprecation (from lancedb>=0.5.4->crewai_tools)\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from lancedb>=0.5.4->crewai_tools) (24.2)\n",
      "Collecting pyarrow>=14 (from lancedb>=0.5.4->crewai_tools)\n",
      "  Using cached pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.12.0->crewai_tools) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.12.0->crewai_tools) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.12.0->crewai_tools) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai>=1.12.0->crewai_tools) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.6.1->crewai_tools) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.6.1->crewai_tools) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.6.1->crewai_tools) (0.4.0)\n",
      "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai_tools)\n",
      "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from requests>=2.31.0->crewai_tools) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from requests>=2.31.0->crewai_tools) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from requests>=2.31.0->crewai_tools) (2025.4.26)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cryptography>=43.0.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from auth0-python>=4.7.1->crewai>=0.119.0->crewai_tools) (45.0.1)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from auth0-python>=4.7.1->crewai>=0.119.0->crewai_tools) (2.10.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai_tools) (2.7)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from build>=1.0.3->chromadb>=0.4.22->crewai_tools) (1.2.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai_tools) (5.5.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpx>=0.27.0->chromadb>=0.4.22->crewai_tools) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.22->crewai_tools) (0.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from instructor>=1.3.3->crewai>=0.119.0->crewai_tools) (0.16)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.40.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (0.10)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (0.3.60)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pandas>=1.4.3 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai_tools) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai_tools) (0.23.0)\n",
      "Collecting pytz<2025.0,>=2024.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (1.14.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openpyxl>=3.1.5->crewai>=0.119.0->crewai_tools) (2.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.22->crewai_tools) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.33.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai_tools) (1.33.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (0.54b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.54b1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (0.54b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai_tools) (3.8.1)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pdfplumber>=0.11.4->crewai>=0.119.0->crewai_tools) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pdfplumber>=0.11.4->crewai>=0.119.0->crewai_tools) (11.2.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pdfplumber>=0.11.4->crewai>=0.119.0->crewai_tools) (4.30.1)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.4.22->crewai_tools)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from posthog>=2.4.0->chromadb>=0.4.22->crewai_tools) (2.2.1)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (9.2.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (4.0.5)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (2.19.1)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached greenlet-3.2.2-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from tokenizers->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (0.31.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from typer>=0.9.0->chromadb>=0.4.22->crewai_tools) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai_tools) (15.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from aiohttp->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (1.20.0)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached fastavro-1.10.0-cp312-cp312-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.119.0->crewai_tools) (1.17.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (2025.3.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (3.21.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (3.0.51)\n",
      "Requirement already satisfied: stack_data in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.68.0->crewai>=0.119.0->crewai_tools) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.22->crewai_tools) (0.25.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (1.33)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.22->crewai_tools) (0.1.2)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from cffi>=1.14->cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.119.0->crewai_tools) (2.22)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai_tools) (3.5.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools) (3.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.22->crewai_tools) (0.6.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.119.0->crewai_tools) (0.2.3)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai_tools)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Using cached crewai_tools-0.45.0-py3-none-any.whl (602 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached embedchain-0.1.128-py3-none-any.whl (211 kB)\n",
      "Using cached chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
      "Using cached lancedb-0.22.0-cp39-abi3-win_amd64.whl (33.0 MB)\n",
      "Using cached pyright-1.1.400-py3-none-any.whl (5.6 MB)\n",
      "Using cached pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Using cached alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Using cached gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
      "Using cached langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "Using cached mem0ai-0.1.99-py3-none-any.whl (145 kB)\n",
      "Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Using cached posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
      "Using cached pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "Using cached pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Using cached sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached cohere-5.15.0-py3-none-any.whl (259 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached greenlet-3.2.2-cp312-cp312-win_amd64.whl (296 kB)\n",
      "Using cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached fastavro-1.10.0-cp312-cp312-win_amd64.whl (487 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'error'\n",
      "Failed to build chroma-hnswlib\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'hnswlib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for chroma-hnswlib\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (chroma-hnswlib)\n"
     ]
    }
   ],
   "source": [
    "pip install crewai_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fe4ab0-4fec-45fb-b820-198d429e7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6564226-bb66-4bc8-99b0-cf3a204c179d",
   "metadata": {},
   "source": [
    "## Step 02. Importing modules, LLMs, tools\n",
    "\n",
    "**NOTE:** To create Agent class objects, we need to specify OPEN_AI model name and api key as environment variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859edfa7-e964-450b-bd95-6ac0f399a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Agent, Task\n",
    "\n",
    "# import os\n",
    "# os.environ['OPENAI_MODEL_NAME'] = \"gpt-4-turbo\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"Your OPEN AI Api Key\"\n",
    "# os.environ['SERPER_API_KEY'] = \"Your Server API key\"\n",
    "\n",
    "import os\n",
    "\n",
    "#from langchain_community.chat_models import AzureChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY_EXT=\"f21b6916332f72245df2484f57aa7aaa589d48868fd0842ebb3b1ed55b4b61077f795dc9a2e951738ae0c6752e5037b5281055d\"\n",
    "OPENAI_API_BASE_EXT=\"dallas-int-prod.com/coreapi/openai/v1\"\n",
    "# Initialize Azure OpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    openai_api_key=OPENAI_API_KEY_EXT,\n",
    "    openai_api_base=OPENAI_API_BASE_EXT,\n",
    "    model=\"mmc-tech-gpt-4o-mini-128k-2024-07-18\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3724d5-4178-44b3-8583-09441e5981d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Using cached langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain_openai)\n",
      "  Using cached langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain_openai) (1.75.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Collecting langsmith<0.4,>=0.1.126 (from langchain-core<1.0.0,>=0.3.59->langchain_openai)\n",
      "  Using cached langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_openai) (9.1.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.59->langchain_openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_openai) (6.0.2)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.59->langchain_openai)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_openai) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain_openai) (2.11.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain_openai) (3.10.18)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain_openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.59->langchain_openai)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.59->langchain_openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
      "Using cached langchain_openai-0.3.17-py3-none-any.whl (62 kB)\n",
      "Using cached langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Installing collected packages: zstandard, packaging, jsonpatch, requests-toolbelt, langsmith, langchain-core, langchain_openai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed jsonpatch-1.33 langchain-core-0.3.60 langchain_openai-0.3.17 langsmith-0.3.42 packaging-24.2 requests-toolbelt-1.0.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727828d-be6a-46f6-83ce-e40e5f20dd94",
   "metadata": {},
   "source": [
    "### crewAI Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed8bb1f-8e51-498e-affa-1409a4629a35",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'crewai_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcrewai_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ScrapeWebsiteTool, SerperDevTool\n\u001b[32m      3\u001b[39m search_tool = SerperDevTool()\n\u001b[32m      4\u001b[39m scrape_tool = ScrapeWebsiteTool()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'crewai_tools'"
     ]
    }
   ],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "\n",
    "search_tool = SerperDevTool()\n",
    "scrape_tool = ScrapeWebsiteTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72cd618-1a00-4da6-892f-950f6ad930e4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chroma-hnswlib\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\aashi-gupta1\\python312\\lib\\site-packages (from chroma-hnswlib) (2.2.5)\n",
      "Building wheels for collected packages: chroma-hnswlib\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'error'\n",
      "Failed to build chroma-hnswlib\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'hnswlib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for chroma-hnswlib\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (chroma-hnswlib)\n"
     ]
    }
   ],
   "source": [
    "pip install chroma-hnswlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068008fb-417d-4625-8d8f-7025b9c9a166",
   "metadata": {},
   "source": [
    "## Step 03. Creating Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdab165-92d5-4494-b005-44e6d7ab18a0",
   "metadata": {},
   "source": [
    "### Agent 1: Research Agent\n",
    "\n",
    "- Researcher Agent \n",
    "- Analyzer Agent\n",
    "- Writer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42b5675-8828-4284-b2d5-c168f07d7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    role=\"Researcher\",\n",
    "\n",
    "    goal=\"Autonomously research complex topics, synthesize information from multiple sources, \"\n",
    "         \"and generate comprehensive reports that demonstrate insights and actionable recommendations.\",\n",
    "    backstory=\"With expertise in multi-agent collaboration, this agent specializes in synthesizing \"\n",
    "              \"information from diverse sources. Utilizing advanced planning, reasoning, and task decomposition, \"\n",
    "              \"the Researcher Agent coordinates with specialized agents to gather, analyze, and present data, \"\n",
    "              \"ensuring thorough and insightful reports that inform decision-making.\",\n",
    "    allow_delegation=True,\n",
    "    verbose=True,\n",
    "    # tools=[search_tool, scrape_tool]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c7a47-91c4-4fe4-af8d-cb663effa54e",
   "metadata": {},
   "source": [
    "### Agent 2: Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3b1f13-c421-4f88-8916-45c52973e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_agent = Agent(\n",
    "    role=\"Analyzer\",\n",
    "    goal=\"Analyze and interpret complex data to extract meaningful insights,\"\n",
    "        \"identify patterns, and support data-driven decision-making across various domains.\",\n",
    "    backstory=\"Equipped with a deep understanding of data \"\n",
    "              \"research and quantitative analysis, this agent \"\n",
    "              \"devises and refines the output. It evaluates \"\n",
    "              \"the data of different searches to determine \"\n",
    "              \"the most appropriate and risk-averse options.\",\n",
    "    allow_delegation=True,\n",
    "    # tools=[search_tool, scrape_tool],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cd5b1-f05b-43d0-9c97-e8d8e1364675",
   "metadata": {},
   "source": [
    "### Agent 3: Execution Agent / Writer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8eab0e5-445a-4656-a0cd-ae7864485fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_agent = Agent(\n",
    "    role=\"Writer Agent\",\n",
    "    goal=\"Craft clear, concise, and engaging reports and documents \"\n",
    "    \"that effectively communicate complex information and insights to diverse audiences.\",\n",
    "    backstory=\"With a talent for storytelling and a deep understanding of various subject matters,\"\n",
    "    \"the Writer Agent specializes in translating intricate data and analyses into accessible narratives.\"\n",
    "    \"By collaborating with research and analysis agents,\"\n",
    "    \"this agent ensures that the final outputs are not only informative but also compelling, \"\n",
    "    \"making complex topics understandable and actionable for stakeholders.\",\n",
    "    allow_delegation=True,\n",
    "    # tools=[search_tool, scrape_tool],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a763458-7122-4017-976a-a08cd83d0733",
   "metadata": {},
   "source": [
    "## Step 04. Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969bc86e-36a7-48cc-8795-a5f54c988039",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Conduct in-depth research on the selected topic ({topic_selection}). \"\n",
    "        \"Synthesize information from multiple sources to gather insights and \"\n",
    "        \"generate a comprehensive report that addresses key questions and findings.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A detailed report summarizing the research findings, \"\n",
    "        \"including insights, conclusions, and actionable recommendations for {topic_selection}.\"\n",
    "    ),\n",
    "    agent=research_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb48c3a-330d-4f4f-8fd6-b75d3429cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the collected data related to {data_source} to identify patterns, \"\n",
    "        \"trends, and correlations. Utilize statistical methods and machine learning techniques \"\n",
    "        \"to derive meaningful insights that can inform strategic decisions.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A set of analytical insights, including identified trends, patterns, \"\n",
    "        \"and potential implications for decision-making regarding {data_source}.\"\n",
    "    ),\n",
    "    agent=analyzer_agent,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2450af3-1988-4d6a-afb1-07387c0ebf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_task = Task(\n",
    "    description=(\n",
    "        \"Draft a clear and engaging report based on the insights gathered from the research \"\n",
    "        \"and analysis of {topic_selection}. Ensure that the document is tailored to the target audience \"\n",
    "        \"and effectively communicates the key findings and recommendations.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A polished report that presents the research and analysis findings in a compelling manner, \"\n",
    "        \"including an executive summary, detailed sections, and clear conclusions for {topic_selection}.\"\n",
    "    ),\n",
    "    agent=execution_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a5aa3-57de-48f4-8d21-fb67e0bb5b4e",
   "metadata": {},
   "source": [
    "## Step 06. Creating Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab4a20-81f9-4c0c-993a-0beb40bc0fa4",
   "metadata": {},
   "source": [
    "### Creating the Crew\n",
    "- The `Process` class helps to delegate the workflow to the Agents (kind of like a Manager at work)\n",
    "- In the example below, it will run this hierarchically.\n",
    "- `manager_llm` lets you choose the \"manager\" LLM you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97bd5ca8-21b8-4d37-9f02-b2c4fb19df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2699c242-6175-4eca-9e75-0c08d9be695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the crew with agent and tasks\n",
    "research_assistant_crew = Crew (\n",
    "    agents=[research_agent, \n",
    "            analyzer_agent, \n",
    "            execution_agent],\n",
    "    \n",
    "    tasks=[research_task, \n",
    "           data_analysis_task, \n",
    "           writing_task],\n",
    "    \n",
    "    verbose=True,\n",
    "    process=Process.hierarchical,\n",
    "    manager_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c0f44-4d6e-45f2-bdfb-1ca8f3d02ee5",
   "metadata": {},
   "source": [
    "### Running the crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb9fff12-a651-4deb-bac0-f336c25f9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # specify the input for crew\n",
    "# financial_trading_inputs = {\n",
    "#     'stock_selection': 'AAPL',\n",
    "#     'initial_capital': '100000',\n",
    "#     'risk_tolerance': 'Medium',\n",
    "#     'trading_strategy_preference': 'Day Trading',\n",
    "#     'news_impact_consideration': True\n",
    "# }\n",
    "\n",
    "research_assistant_inputs = {\n",
    "    'topic_selection': 'Impact of Market Trends on Technology Stocks',\n",
    "    'data_source': 'Recent Market Data and Financial Reports',\n",
    "    'audience': 'Investment Analysts and Stakeholders',\n",
    "    'report_format': 'Executive Summary with Detailed Analysis',\n",
    "    'research_depth': 'Comprehensive',\n",
    "    'analysis_techniques': ['Statistical Analysis', 'Machine Learning'],\n",
    "    'writing_style': 'Professional and Engaging'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfbd2934-c7ff-4d4e-8aa5-1df2dde548f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\"> Crew Execution Started </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">36542fce-128e-4dcb-a8db-0709a150a3c4</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"></span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\u001b[0m\u001b[36m\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m\u001b[0m\u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m                                                                                                                 \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m36542fce-128e-4dcb-a8db-0709a150a3c4\u001b[0m                                                                       \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m                                                                                                                 \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m                                                                                                                 \u001b[36m\u001b[0m\n",
       "\u001b[36m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Crew: crew</span>\n",
       " <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Task: 4e51da14-2859-4382-81a5-371d04746ad9</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       " \u001b[1;33m Task: 4e51da14-2859-4382-81a5-371d04746ad9\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Crew: crew</span>\n",
       " <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Task: 4e51da14-2859-4382-81a5-371d04746ad9</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       " \u001b[1;33m Task: 4e51da14-2859-4382-81a5-371d04746ad9\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
       "     \u001b[1;32m Agent: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mConduct in-depth research on the selected topic (Impact of Market Trends on Technology Stocks). Synthesize information from multiple sources to gather insights and generate a comprehensive report that addresses key questions and findings.\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       " <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> </span><span style=\"color: #000080; text-decoration-color: #000080\">Thinking...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m Agent: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
       "\u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       " \u001b[1;34m \u001b[0m\u001b[34mThinking...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Crew: crew</span>\n",
       " <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Task: 4e51da14-2859-4382-81a5-371d04746ad9</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> LLM Failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       " \u001b[1;33m Task: 4e51da14-2859-4382-81a5-371d04746ad9\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
       "     \u001b[1;32m Agent: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       "         \u001b[1;31m LLM Failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> LLM Error </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. </span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000\">You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000\"> Pass model as E.g. For 'Huggingface' inference endpoints pass in </span>                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000\">`completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers</span>              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[1;31m LLM Call Failed\u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mlitellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. \u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[31mYou passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\u001b[0m                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[31m Pass model as E.g. For 'Huggingface' inference endpoints pass in \u001b[0m                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[31m`completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[0m              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Error during LLM call: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[00m\n",
      "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
      "\u001b[91m Error details: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Crew: crew</span>\n",
       " <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Task: 4e51da14-2859-4382-81a5-371d04746ad9</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Assigned to: </span><span style=\"color: #800000; text-decoration-color: #800000\">Crew Manager</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Failed</span>\n",
       "     <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Crew Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "         <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> LLM Failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       " \u001b[1;31m Task: 4e51da14-2859-4382-81a5-371d04746ad9\u001b[0m\n",
       "    \u001b[37m   Assigned to: \u001b[0m\u001b[31mCrew Manager\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[1;31m Failed\u001b[0m\n",
       "     \u001b[1;32m Agent: \u001b[0m\u001b[32mCrew Manager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       "         \u001b[1;31m LLM Failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> Task Failure </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Task Failed</span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">4e51da14-2859-4382-81a5-371d04746ad9</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #800000; text-decoration-color: #800000\">Crew Manager</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31m4e51da14-2859-4382-81a5-371d04746ad9\u001b[0m                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mCrew Manager\u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> Crew Failure </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Crew Execution Failed</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">crew</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #800000; text-decoration-color: #800000\">36542fce-128e-4dcb-a8db-0709a150a3c4</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31m36542fce-128e-4dcb-a8db-0709a150a3c4\u001b[0m                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### this execution will take some time to run\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mresearch_assistant_crew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresearch_assistant_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\crew.py:665\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    663\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_sequential_process()\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_hierarchical_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    668\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe process \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.process\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not implemented yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    669\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\crew.py:780\u001b[39m, in \u001b[36mCrew._run_hierarchical_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates and assigns a manager agent to make sure the crew completes the tasks.\"\"\"\u001b[39;00m\n\u001b[32m    779\u001b[39m \u001b[38;5;28mself\u001b[39m._create_manager_agent()\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\crew.py:878\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m    875\u001b[39m     futures.clear()\n\u001b[32m    877\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m task_outputs.append(task_output)\n\u001b[32m    884\u001b[39m \u001b[38;5;28mself\u001b[39m._process_task_result(task, task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\task.py:347\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sync\u001b[39m(\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    342\u001b[39m     agent: Optional[BaseAgent] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    343\u001b[39m     context: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    344\u001b[39m     tools: Optional[List[BaseTool]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    345\u001b[39m ) -> TaskOutput:\n\u001b[32m    346\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\task.py:491\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28mself\u001b[39m.end_time = datetime.datetime.now()\n\u001b[32m    490\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\task.py:411\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_by_agents.add(agent.role)\n\u001b[32m    410\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m pydantic_output, json_output = \u001b[38;5;28mself\u001b[39m._export_output(result)\n\u001b[32m    418\u001b[39m task_output = TaskOutput(\n\u001b[32m    419\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    420\u001b[39m     description=\u001b[38;5;28mself\u001b[39m.description,\n\u001b[32m   (...)\u001b[39m\u001b[32m    426\u001b[39m     output_format=\u001b[38;5;28mself\u001b[39m._get_output_format(),\n\u001b[32m    427\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agent.py:387\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    378\u001b[39m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m    379\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    380\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    381\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m         ),\n\u001b[32m    386\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m._times_executed += \u001b[32m1\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._times_executed > \u001b[38;5;28mself\u001b[39m.max_retry_limit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agent.py:363\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    359\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._execute_with_timeout(\n\u001b[32m    360\u001b[39m             task_prompt, task, \u001b[38;5;28mself\u001b[39m.max_execution_time\n\u001b[32m    361\u001b[39m         )\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    366\u001b[39m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n\u001b[32m    367\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    369\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m         ),\n\u001b[32m    374\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agent.py:459\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_without_timeout\u001b[39m(\u001b[38;5;28mself\u001b[39m, task_prompt: \u001b[38;5;28mstr\u001b[39m, task: Task) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    450\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute a task without a timeout.\u001b[39;00m\n\u001b[32m    451\u001b[39m \n\u001b[32m    452\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m \u001b[33;03m        The output of the agent.\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:123\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    120\u001b[39m handle_unknown_error(\u001b[38;5;28mself\u001b[39m._printer, e)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:112\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.ask_for_human_input = \u001b[38;5;28mbool\u001b[39m(inputs.get(\u001b[33m\"\u001b[39m\u001b[33mask_for_human_input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m._printer.print(\n\u001b[32m    115\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:208\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_context_length_exceeded(e):\n\u001b[32m    210\u001b[39m         handle_context_length(\n\u001b[32m    211\u001b[39m             respect_context_window=\u001b[38;5;28mself\u001b[39m.respect_context_window,\n\u001b[32m    212\u001b[39m             printer=\u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m             i18n=\u001b[38;5;28mself\u001b[39m._i18n,\n\u001b[32m    217\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:155\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m     formatted_answer = handle_max_iterations_exceeded(\n\u001b[32m    145\u001b[39m         formatted_answer,\n\u001b[32m    146\u001b[39m         printer=\u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         callbacks=\u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m    151\u001b[39m     )\n\u001b[32m    153\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m formatted_answer = process_llm_response(answer, \u001b[38;5;28mself\u001b[39m.use_stop_words)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Extract agent fingerprint if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py:157\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    153\u001b[39m     printer.print(\n\u001b[32m    154\u001b[39m         content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[32m    159\u001b[39m     printer.print(\n\u001b[32m    160\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mReceived None or empty response from LLM call.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    161\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    162\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\utilities\\agent_utils.py:148\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    153\u001b[39m     printer.print(\n\u001b[32m    154\u001b[39m         content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\llm.py:890\u001b[39m, in \u001b[36mLLM.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions)\u001b[39m\n\u001b[32m    886\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_streaming_response(\n\u001b[32m    887\u001b[39m             params, callbacks, available_functions\n\u001b[32m    888\u001b[39m         )\n\u001b[32m    889\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m890\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_non_streaming_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_functions\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LLMContextLengthExceededException:\n\u001b[32m    895\u001b[39m     \u001b[38;5;66;03m# Re-raise LLMContextLengthExceededException as it should be handled\u001b[39;00m\n\u001b[32m    896\u001b[39m     \u001b[38;5;66;03m# by the CrewAgentExecutor._invoke_loop method, which can then decide\u001b[39;00m\n\u001b[32m    897\u001b[39m     \u001b[38;5;66;03m# whether to summarize the content or abort based on the respect_context_window flag\u001b[39;00m\n\u001b[32m    898\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\crewai\\llm.py:729\u001b[39m, in \u001b[36mLLM._handle_non_streaming_response\u001b[39m\u001b[34m(self, params, callbacks, available_functions)\u001b[39m\n\u001b[32m    723\u001b[39m \u001b[38;5;66;03m# --- 1) Make the completion call\u001b[39;00m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    725\u001b[39m     \u001b[38;5;66;03m# Attempt to make the completion call, but catch context window errors\u001b[39;00m\n\u001b[32m    726\u001b[39m     \u001b[38;5;66;03m# and convert them to our own exception type for consistent handling\u001b[39;00m\n\u001b[32m    727\u001b[39m     \u001b[38;5;66;03m# across the codebase. This allows CrewAgentExecutor to handle context\u001b[39;00m\n\u001b[32m    728\u001b[39m     \u001b[38;5;66;03m# length issues appropriately.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m     response = \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# Convert litellm's context window error to our own exception type\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# for consistent handling in the rest of the codebase\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededException(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\utils.py:1255\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1252\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1253\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1254\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\utils.py:1133\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\main.py:3216\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3215\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3216\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[32m   3217\u001b[39m         model=model,\n\u001b[32m   3218\u001b[39m         custom_llm_provider=custom_llm_provider,\n\u001b[32m   3219\u001b[39m         original_exception=e,\n\u001b[32m   3220\u001b[39m         completion_kwargs=args,\n\u001b[32m   3221\u001b[39m         extra_kwargs=kwargs,\n\u001b[32m   3222\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\main.py:1031\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   1029\u001b[39m     model = deployment_id\n\u001b[32m   1030\u001b[39m     custom_llm_provider = \u001b[33m\"\u001b[39m\u001b[33mazure\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m model, custom_llm_provider, dynamic_api_key, api_base = \u001b[43mget_llm_provider\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1039\u001b[39m     provider_specific_header \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m provider_specific_header[\u001b[33m\"\u001b[39m\u001b[33mcustom_llm_provider\u001b[39m\u001b[33m\"\u001b[39m] == custom_llm_provider\n\u001b[32m   1041\u001b[39m ):\n\u001b[32m   1042\u001b[39m     headers.update(provider_specific_header[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py:360\u001b[39m, in \u001b[36mget_llm_provider\u001b[39m\u001b[34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, litellm.exceptions.BadRequestError):\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m         error_str = (\n\u001b[32m    363\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGetLLMProvider Exception - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33moriginal model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    364\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\python312\\Lib\\site-packages\\litellm\\litellm_core_utils\\get_llm_provider_logic.py:337\u001b[39m, in \u001b[36mget_llm_provider\u001b[39m\u001b[34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[39m\n\u001b[32m    335\u001b[39m     error_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Pass model as E.g. For \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHuggingface\u001b[39m\u001b[33m'\u001b[39m\u001b[33m inference endpoints pass in `completion(model=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhuggingface/starcoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m,..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m     \u001b[38;5;66;03m# maps to openai.NotFoundError, this is raised when openai does not recognize the llm\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m litellm.exceptions.BadRequestError(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    338\u001b[39m         message=error_str,\n\u001b[32m    339\u001b[39m         model=model,\n\u001b[32m    340\u001b[39m         response=httpx.Response(\n\u001b[32m    341\u001b[39m             status_code=\u001b[32m400\u001b[39m,\n\u001b[32m    342\u001b[39m             content=error_str,\n\u001b[32m    343\u001b[39m             request=httpx.Request(method=\u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m, url=\u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/BerriAI/litellm\u001b[39m\u001b[33m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    344\u001b[39m         ),\n\u001b[32m    345\u001b[39m         llm_provider=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    346\u001b[39m     )\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(api_base, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    349\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi base needs to be a string. api_base=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(api_base)\n\u001b[32m    350\u001b[39m     )\n",
      "\u001b[31mBadRequestError\u001b[39m: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=mmc-tech-gpt-4o-mini-128k-2024-07-18\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
     ]
    }
   ],
   "source": [
    "### this execution will take some time to run\n",
    "result = research_assistant_crew.kickoff(inputs=research_assistant_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4de41c-be8b-47a5-869d-69480df6f509",
   "metadata": {},
   "source": [
    "- Display the final result as Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82d81b94-9f3b-4020-ab5f-43d86cf23c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The comprehensive risk analysis report and mitigation recommendations for day trading AAPL are as follows:\n",
       "\n",
       "Risk Analysis:\n",
       "- **Volume and Liquidity**: Fluctuating trading volumes and liquidity patterns in AAPL indicate potential increased trade costs and price slippage risks.\n",
       "- **Volatility**: Market shifts influenced by broader economic indicators and policy decisions may lead to sudden price changes in AAPL.\n",
       "- **Price Segment**: High performance attracting speculative trading in AAPL can result in increased price volatility.\n",
       "- **Macro Factors**: International trade adjustments and political impacts can indirectly affect market sentiment and AAPLs stock performance.\n",
       "- **News and Events**: Any news related to AAPL or its sector can cause sharp movements in stock price.\n",
       "\n",
       "Mitigation Strategies:\n",
       "1. **Two-Day High/Low Strategy**: Buying breakouts from a two-day high or selling breakdowns from a two-day low with a 1:2 risk/reward ratio and strict stop-loss measures.\n",
       "2. **Trading Ranges During Low Volatility**: Utilizing oscillators to identify overbought and oversold levels during low volatility periods.\n",
       "3. **GAP-FILL Strategy**: Trading the gaps between the previous day's close and the current day's open, aiming to fill these gaps with strategic entry and exit points.\n",
       "\n",
       "These strategies emphasize preparation, discipline, and risk management to navigate the risks associated with day trading AAPL effectively. Traders should stay informed about market conditions, economic indicators, and company-specific news to make informed decisions and optimize their trading experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d535074-a99e-47ab-b7f4-d4075f60610d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (python312)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
